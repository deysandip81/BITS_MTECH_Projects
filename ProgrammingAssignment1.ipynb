{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deysandip81/BITS_MTECH_Projects/blob/main/ProgrammingAssignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Models For Classification\n",
        "\n",
        "In this notebook we look at how to implement linear models in python.\n",
        "\n",
        "The following datasets will be used for analysis -\n",
        "\n",
        "1. [Bikeshare](https://drive.google.com/file/d/1mzUgrPg3Dndy-DFy8rf6Dqh6-jX1FaSe/view?usp=sharing)\n",
        "2. [Stock-Market](https://drive.google.com/file/d/1bFNQ0DzvFAbNKa5G8PA-aLRo35xSYSBC/view?usp=sharing)\n",
        "\n",
        "\n",
        "From before we use the \n",
        "\n",
        "1. `numpy` library for dealing with numerical datasets\n",
        "2. `pandas` is used to manipilate the datasets using the DataFrame object.\n",
        "3. `matplotlib` is used to plot the figures.\n",
        "4. Use `sklearn` to implement logistic regression\n"
      ],
      "metadata": {
        "id": "6hqgxlSM9CeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/\"\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"Notebooks/Data/Smarket.csv\"\n",
        "\n",
        "def fetch_data(housing_url=HOUSING_URL):\n",
        "    urllib.request.urlretrieve(housing_url, \"/content/Smarket.csv\")\n",
        "\n",
        "fetch_data()"
      ],
      "metadata": {
        "id": "I-8xQ4d21lAq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cT0j34pJ8Lkd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First lets look at the stock market data. The aim is to predict the `Direction` variable using `lag_*` and `Volume` variables.\n",
        "\n",
        "Before any analysis can be done we need to prepare the data by -\n",
        "\n",
        "1. Encoding the output/response Up/Down as 0/1.\n",
        "2. We then remove the `Year`, `Today` and `Direction` to get our independent variables.\n",
        "3. Note that the sign of `Today` essentially dictates the Up/Down direction."
      ],
      "metadata": {
        "id": "AC8j3Omj9b2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/Smarket.csv\", index_col=0)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgeyusYf9jir",
        "outputId": "7f2baea7-e5c6-4a57-b994-522484b3d32f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
            "1  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
            "2  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
            "3  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
            "4  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
            "5  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 : Write a function which takes a pandas dataframe, and column name and returns the mean, stdev, 25th Quantile, Median, 75th Quantile.\n",
        "\n",
        "**IMPORTANT NOTE**: The function you have written should pass the test. Only those which have passed will be considered for grades. An example is shown below. "
      ],
      "metadata": {
        "id": "1t6OmzRw-OYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def column_stats(data, col_name):\n",
        "  ### CODE HERE\n",
        "  ### Fill this function such that given a pandas datafarme data,\n",
        "  ### and column name col_name it will pass the test below.\n",
        "\n",
        "  ### Getting the mean\n",
        "  mean = data[col_name].mean()\n",
        "  \n",
        "  ### Getting the Std Deviation\n",
        "  stdev = data[col_name].std() \n",
        "\n",
        "  ### Getting the 25th Quantile\n",
        "  Q1 = data[col_name].quantile(0.25)\n",
        "\n",
        "  ### Getting the median\n",
        "  median = data[col_name].median()\n",
        "\n",
        "  ### Getting the 75 Quantile\n",
        "  Q3 = data[col_name].quantile(0.75)\n",
        "\n",
        "  #print(\"The values are \"+str(mean)+\", \"+str(stdev)+\", \"+str(Q1)+\", \"+str(median)+\", \"+str(Q3))\n",
        "  return mean,stdev,Q1,median,Q3\n",
        "  \n",
        "  \n",
        "\n",
        "def test_column_stats():\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  data = pd.read_csv(\"/content/Smarket.csv\", index_col=0)\n",
        "  mean, stdev, Q1, median, Q3 = column_stats(data, 'Lag1')\n",
        "  assert np.abs(mean - 0.003834) < 1e-4\n",
        "  assert np.abs(stdev-1.136299) < 1e-4\n",
        "  assert np.abs(Q1 - -0.639500) < 1e-4\n",
        "  assert np.abs(median-0.039000) < 1e-4\n",
        "  assert np.abs(Q3-0.596750) < 1e-4\n",
        "  print(\"Testcase Execution Report\")\n",
        "  print(\"-------------------------\")\n",
        "  print(\"Success ! All the testcases of ColumnStats passed\")\n",
        "\n",
        "\n",
        "test_column_stats()"
      ],
      "metadata": {
        "id": "9rTd0fEt-uV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49601a7-d0c9-4754-f81b-0e347008795d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testcase Execution Report\n",
            "-------------------------\n",
            "Success ! All the testcases of ColumnStats passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Split the dataset into train and test with sizes 998, 252 respectively.  Then fit a logistic regression model on this dataset.\n",
        "\n",
        "Report the following:\n",
        "\n",
        "1. Train Accuracy\n",
        "2. Test Accuracy\n",
        "3. `coef_` attribute\n",
        "4. `intercept_` attribute.\n",
        "\n",
        "Make sure the output is just the above quantities and nothing else.\n",
        "\n",
        "**IMPORTANT NOTE 1:** Do not shuffle the dataset while splitting. The first 998 rows should be taken as train and remaining 252 should be taken as test.\n",
        "\n",
        "**IMPORTANT NOTE 2:** Do not use the `Year` and `Today` for prediction.\n",
        "\n",
        "**IMPORTANT NOTE 3:** Consider `Up` to be class 1 and `Down` to be class 0.\n",
        "\n",
        "** Grading will be done on whether the test `test_classifier` function worked or not.\n"
      ],
      "metadata": {
        "id": "YKKpFbdmCA4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing\n",
        "from sklearn import utils\n",
        "from sklearn import metrics \n",
        "\n",
        "\n",
        "def get_LR_classifier():\n",
        "  ### CODE HERE\n",
        "\n",
        "  ### Dropping the column Year and Today from the dataset as they are not going to be used for prediction\n",
        "  df = data.drop([\"Year\",\"Today\"], axis=1)\n",
        "\n",
        "  ### Using label encoder to use 0/1 encoding for the column Direction\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  le.fit(df.Direction)\n",
        "  df['Direction'] = le.transform(df.Direction)\n",
        "\n",
        "  #print(df.head())\n",
        "\n",
        "  ### Creating y (dependant variable) and x (independent variables) for the algorithm to work\n",
        "  y = df['Direction']\n",
        "  x = df.drop('Direction', axis=1)\n",
        "\n",
        "  #print(x.head())\n",
        "  #print(y.head())\n",
        "\n",
        "  ### Creating Test and Train split as per the requirement\n",
        "  XTrain, XTest, yTrain,yTest=train_test_split(x,y,train_size = 998,test_size=252,shuffle = False)\n",
        "  \n",
        "  ### Training a logistic regression model\n",
        "  clf = LogisticRegression()\n",
        "  clf.fit(XTrain, yTrain)\n",
        "  \n",
        "  # Reporting & Analysis\n",
        "  print(\"Run Report\")\n",
        "  print(\"-------------------\")\n",
        "  print(\"Train Accuracy:\")\n",
        "  print(clf.score(XTrain, yTrain))\n",
        "  print()\n",
        "  print(\"Test Accuracy:\")\n",
        "  print(clf.score(XTest, yTest))\n",
        "  print()\n",
        "  print(\"coef_ attribute:\")\n",
        "  print(np.array(clf.coef_))\n",
        "  print()\n",
        "  print(\"intercept_ attribute:\")\n",
        "  print(clf.intercept_)\n",
        "  print()\n",
        "  print(\"[Optional]Confusion Matrix:\")\n",
        "  yPred=clf.predict(XTest) \n",
        "  cnf_matrix = metrics.confusion_matrix(yTest, yPred) \n",
        "  print(cnf_matrix)\n",
        "\n",
        "  ### Returning the required values\n",
        "  return clf, XTrain, yTrain, XTest, yTest\n",
        "\n",
        "def test_LR_classifier():\n",
        "  clf, XTrain, yTrain, XTest, yTest = get_LR_classifier()\n",
        "  assert np.abs(clf.score(XTrain, yTrain) - 0.5250501002004008) < 1e-4\n",
        "  assert np.abs(clf.score(XTest, yTest) - 0.48412698412698413) < 1e-4\n",
        "  arr = np.array([[-0.05410202, -0.04559333,  0.00727805,  0.00653897, -0.00415829, -0.10995391]])\n",
        "  assert np.sum(np.abs(np.array(clf.coef_) - arr)) <6*1e-4\n",
        "  assert np.abs(clf.intercept_ - 0.18259423) < 1e-4\n",
        "\n",
        "  print()\n",
        "  print(\"Testcase Execution Report\")\n",
        "  print(\"----------------------------\")\n",
        "  print(\"Success ! All the testcases of LogisticRegression passed\")\n",
        "\n",
        "\n",
        "test_LR_classifier()"
      ],
      "metadata": {
        "id": "EDIBI0KDCpAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5299218-ac09-4ca4-d1be-e3819175f634"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run Report\n",
            "-------------------\n",
            "Train Accuracy:\n",
            "0.5250501002004008\n",
            "\n",
            "Test Accuracy:\n",
            "0.48412698412698413\n",
            "\n",
            "coef_ attribute:\n",
            "[[-0.05410202 -0.04559333  0.00727805  0.00653897 -0.00415829 -0.10995391]]\n",
            "\n",
            "intercept_ attribute:\n",
            "[0.18259423]\n",
            "\n",
            "[Optional]Confusion Matrix:\n",
            "[[74 37]\n",
            " [93 48]]\n",
            "\n",
            "Testcase Execution Report\n",
            "----------------------------\n",
            "Success ! All the testcases of LogisticRegression passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Using the sklearn package `from sklearn.naive_bayes.GaussianNB` fit a naive bayes classifier. Use only the features `Lag2` and `Lag3` for this purpose.\n",
        "\n",
        "eport the following quantities from the properties of the classifier:\n",
        "\n",
        "1. `class_prior_`\n",
        "2. `theta_`\n",
        "3. `var_`\n",
        "4. Confusion Matrix for the test data.\n",
        "\n",
        "**IMPORTANT NOTE** The above quantities should be printed with correct labelling. \n"
      ],
      "metadata": {
        "id": "b_oTKH1tDF2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics \n",
        "\n",
        "\n",
        "\n",
        "def get_NB_classifier():\n",
        "  ### CODE HERE\n",
        "\n",
        "  ### Using label encoder to use 0/1 encoding for the column Direction\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  le.fit(data.Direction)\n",
        "  data['Direction'] = le.transform(data.Direction)\n",
        "\n",
        "  #print(df.head())\n",
        "  \n",
        "  ### Creating y (dependant variable) and x (independent variables) for the algorithm to work\n",
        "  y = data['Direction']\n",
        "  x = data[[\"Lag2\",\"Lag3\"]]\n",
        "\n",
        "  ### Creating Test and Train split as per the requirement\n",
        "  X_train, X_test, y_train,y_test=train_test_split(x,y,train_size = 998,test_size=252,shuffle = False)\n",
        "\n",
        "  ### Training a GaussianNB  model\n",
        "  clf = GaussianNB()\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  # Reporting & Analysis\n",
        "  print(\"Report of Execution\")\n",
        "  print(\"------------------------\")\n",
        "  print(\"class_prior_ attribute:\")\n",
        "  print(np.array(clf.class_prior_))\n",
        "  print()\n",
        "  print(\"theta_ attribute:\")\n",
        "  print(np.array(clf.theta_))\n",
        "  print()\n",
        "  print(\"var_ attribute:\")\n",
        "  print(np.array(np.sqrt(clf.var_)))\n",
        "  print()\n",
        "  print(\"Confusion Matrix:\")\n",
        "  yPred=clf.predict(X_test) \n",
        "  cnf_matrix = metrics.confusion_matrix(y_test, yPred) \n",
        "  print(cnf_matrix)\n",
        "\n",
        "\n",
        "  ### Returning the required values\n",
        "  return clf, X_train, y_train, X_test, y_test\n",
        "\n",
        "def test_NB_classifier():\n",
        "  clf, Xtrain, yTrain, XTest, yTest = get_NB_classifier()\n",
        "  arr1 = np.array([0.49198397, 0.50801603])\n",
        "  assert np.sum(np.abs(np.array(clf.class_prior_) - arr1)) < 2*1e-4\n",
        "\n",
        "  arr2 = np.array([[ 0.03389409, -0.00980652],\n",
        "                    [-0.03132544,  0.00583432]])\n",
        "  assert np.sum(np.abs(np.array(clf.theta_) - arr2)) < 4*1e-4\n",
        "\n",
        "\n",
        "  arr3 = np.array([[1.23792871, 1.23412176],\n",
        "                   [1.21956089, 1.22963]])\n",
        "  assert np.sum(np.abs(np.array(np.sqrt(clf.var_)) - arr3)) <6*1e-4\n",
        "\n",
        "  arr4 = np.array([[  9, 102],\n",
        "                   [  7, 134]])\n",
        "  assert np.sum(np.abs(np.array(arr4) - arr4)) < 4*1e-4 \n",
        "\n",
        "  print()\n",
        "  print(\"Testcase Execution Status\")\n",
        "  print(\"---------------------------\")\n",
        "  print(\"Success ! All the testcases of GaussianNB passed\") \n",
        "\n",
        "test_NB_classifier()  "
      ],
      "metadata": {
        "id": "7yd3Ffs8DE5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0bef99-5b87-4a5a-e8c4-d436c4440c01"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report of Execution\n",
            "------------------------\n",
            "class_prior_ attribute:\n",
            "[0.49198397 0.50801603]\n",
            "\n",
            "theta_ attribute:\n",
            "[[ 0.03389409 -0.00980652]\n",
            " [-0.03132544  0.00583432]]\n",
            "\n",
            "var_ attribute:\n",
            "[[1.23792871 1.23412176]\n",
            " [1.21956089 1.22963   ]]\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  9 102]\n",
            " [  7 134]]\n",
            "\n",
            "Testcase Execution Status\n",
            "---------------------------\n",
            "Success ! All the testcases of GaussianNB passed\n"
          ]
        }
      ]
    }
  ]
}